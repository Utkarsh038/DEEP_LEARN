{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4w75VKlQoLlcxXXLY9yVT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Utkarsh038/DEEP_LEARN/blob/main/BASIC_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1 Artificial Neurons\n",
        "An artificial neuron mimics the behavior of a biological neuron using mathematical computations.\n",
        "\n",
        "Example 1:\n",
        "\n",
        "Biological Neuron vs. Artificial Neuron\n",
        "\n",
        "A biological neuron takes input signals through dendrites, processes them, and sends an output through axons. Similarly, an artificial neuron takes numerical inputs, applies weights, adds bias, and passes through an activation function."
      ],
      "metadata": {
        "id": "Xxy_MXR28TBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# An artificial neuron computes a weighted sum and applies an activation function\n",
        "# à¤à¤• à¤•à¥ƒà¤¤à¥à¤°à¤¿à¤® à¤¨à¥à¤¯à¥‚à¤°à¥‰à¤¨ à¤‡à¤¨à¤ªà¥à¤Ÿ à¤•à¤¾ à¤­à¤¾à¤°à¤¿à¤¤ à¤¯à¥‹à¤— (weighted sum) à¤¨à¤¿à¤•à¤¾à¤²à¤¤à¤¾ à¤¹à¥ˆ à¤”à¤° à¤‰à¤¸à¥‡ à¤à¤• à¤«à¤‚à¤•à¥à¤¶à¤¨ à¤¸à¥‡ à¤ªà¤¾à¤¸ à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆ\n",
        "\n",
        "inputs = np.array([0.5, 0.3])  # Inputs to the neuron (à¤¨à¥à¤¯à¥‚à¤°à¥‰à¤¨ à¤•à¥‹ à¤¦à¤¿à¤ à¤—à¤ à¤‡à¤¨à¤ªà¥à¤Ÿ)\n",
        "weights = np.array([0.8, 0.2])  # Weights assigned to inputs (à¤‡à¤¨à¤ªà¥à¤Ÿ à¤ªà¤° à¤¦à¤¿à¤ à¤—à¤ à¤µà¥‡à¤Ÿà¥à¤¸)\n",
        "bias = 0.1  # Bias term (à¤ªà¥‚à¤°à¥à¤µà¤¾à¤—à¥à¤°à¤¹ - Bias à¤œà¥‹ à¤†à¤‰à¤Ÿà¤ªà¥à¤Ÿ à¤•à¥‹ à¤¶à¤¿à¤«à¥à¤Ÿ à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆ)\n",
        "\n",
        "# Compute weighted sum (à¤­à¤¾à¤°à¤¿à¤¤ à¤¯à¥‹à¤— à¤¨à¤¿à¤•à¤¾à¤²à¤¨à¤¾)\n",
        "output = np.dot(inputs, weights) + bias\n",
        "print(\"Neuron Output:\", output)  # Display output (à¤†à¤‰à¤Ÿà¤ªà¥à¤Ÿ à¤¦à¤¿à¤–à¤¾à¤à¤‚)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-iF6AXo8UGO",
        "outputId": "c86ed7b0-93e5-4b36-9766-797a79e57799"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neuron Output: 0.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example 2: Activation Functions\n",
        "Let's apply different activation functions to the output of an artificial neuron."
      ],
      "metadata": {
        "id": "-IdloZXL82PX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Different activation functions control how a neuron fires.\n",
        "# à¤µà¤¿à¤­à¤¿à¤¨à¥à¤¨ Activation à¤«à¤¼à¤‚à¤•à¥à¤¶à¤¨ à¤¯à¤¹ à¤¨à¤¿à¤°à¥à¤§à¤¾à¤°à¤¿à¤¤ à¤•à¤°à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¤•à¤¿ à¤¨à¥à¤¯à¥‚à¤°à¥‰à¤¨ à¤•à¤¬ à¤”à¤° à¤•à¥ˆà¤¸à¥‡ à¤«à¤¾à¤¯à¤° à¤•à¤°à¥‡à¤—à¤¾à¥¤\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))  # Sigmoid function (à¤†à¤‰à¤Ÿà¤ªà¥à¤Ÿ à¤•à¥‹ 0 à¤”à¤° 1 à¤•à¥‡ à¤¬à¥€à¤š à¤¸à¥à¤•à¥‡à¤² à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆ)\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)  # ReLU function (Negative values à¤•à¥‹ 0 à¤¬à¤¨à¤¾ à¤¦à¥‡à¤¤à¤¾ à¤¹à¥ˆ)\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)  # Tanh function (à¤†à¤‰à¤Ÿà¤ªà¥à¤Ÿ -1 à¤¸à¥‡ 1 à¤•à¥‡ à¤¬à¥€à¤š à¤¦à¥‡à¤¤à¤¾ à¤¹à¥ˆ)\n",
        "\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x))  # Softmax function (à¤®à¤²à¥à¤Ÿà¥€-à¤•à¥à¤²à¤¾à¤¸ à¤ªà¥à¤°à¥‡à¤¡à¤¿à¤•à¥à¤¶à¤¨ à¤•à¥‡ à¤²à¤¿à¤)\n",
        "    return exp_x / exp_x.sum()\n",
        "\n",
        "x = np.array([1.0, 2.0, -1.0])  # Input values (à¤¨à¥à¤¯à¥‚à¤°à¥‰à¤¨ à¤®à¥‡à¤‚ à¤œà¤¾à¤¨à¥‡ à¤µà¤¾à¤²à¥‡ à¤‡à¤¨à¤ªà¥à¤Ÿ)\n",
        "\n",
        "print(\"Sigmoid:\", sigmoid(x))  # Print sigmoid output (à¤¸à¤¿à¤—à¥à¤®à¥‰à¤‡à¤¡ à¤•à¤¾ à¤†à¤‰à¤Ÿà¤ªà¥à¤Ÿ)\n",
        "print(\"ReLU:\", relu(x))  # Print ReLU output (ReLU à¤•à¤¾ à¤†à¤‰à¤Ÿà¤ªà¥à¤Ÿ)\n",
        "print(\"Tanh:\", tanh(x))  # Print Tanh output (Tanh à¤•à¤¾ à¤†à¤‰à¤Ÿà¤ªà¥à¤Ÿ)\n",
        "print(\"Softmax:\", softmax(x))  # Print Softmax output (Softmax à¤•à¤¾ à¤†à¤‰à¤Ÿà¤ªà¥à¤Ÿ)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjLB1TPD86Ee",
        "outputId": "3be0ae19-e397-4a94-a6ae-821a2f02e6db"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sigmoid: [0.73105858 0.88079708 0.26894142]\n",
            "ReLU: [1. 2. 0.]\n",
            "Tanh: [ 0.76159416  0.96402758 -0.76159416]\n",
            "Softmax: [0.25949646 0.70538451 0.03511903]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2 Computational Models of Neurons\n",
        "An artificial neuron follows this equation:\n",
        "\n",
        "\n",
        "    \n",
        "ğ‘¦\n",
        "=\n",
        "ğ‘“\n",
        "(\n",
        "âˆ‘\n",
        "(\n",
        "ğ‘¤\n",
        "ğ‘–\n",
        "ğ‘¥\n",
        "ğ‘–\n",
        ")\n",
        "+\n",
        "ğ‘\n",
        ")\n",
        "y=f(âˆ‘(w\n",
        "i\n",
        "â€‹\n",
        " x\n",
        "i\n",
        "â€‹\n",
        " )+b)\n",
        "\n",
        "\n",
        "\n",
        "Example 3: Weighted Sum and Bias"
      ],
      "metadata": {
        "id": "RqvVPh_d9Caf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.array([0.2, 0.8, -0.5])  # Input values (à¤‡à¤¨à¤ªà¥à¤Ÿà¥à¤¸)\n",
        "weights = np.array([0.3, -0.2, 0.5])  # Weights assigned to inputs (à¤µà¥‡à¤Ÿà¥à¤¸)\n",
        "bias = 0.1  # Bias (Bias à¤µà¥ˆà¤²à¥à¤¯à¥‚ à¤œà¥‹ à¤à¤¡à¤œà¤¸à¥à¤Ÿà¤®à¥‡à¤‚à¤Ÿ à¤•à¥‡ à¤²à¤¿à¤ à¤¦à¥€ à¤œà¤¾à¤¤à¥€ à¤¹à¥ˆ)\n",
        "\n",
        "# Compute weighted sum (à¤µà¥‡à¤Ÿà¥‡à¤¡ à¤¸à¤® à¤¨à¤¿à¤•à¤¾à¤²à¤¨à¤¾)\n",
        "weighted_sum = np.dot(inputs, weights) + bias\n",
        "print(\"Weighted Sum:\", weighted_sum)  # Print the output (à¤†à¤‰à¤Ÿà¤ªà¥à¤Ÿ à¤¦à¤¿à¤–à¤¾à¤¨à¤¾)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Etrsuvr9Oon",
        "outputId": "60033bfc-87cc-4fc5-ea81-2777878dda22"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted Sum: -0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example 4: Gradient Descent Intuition\n",
        "Gradient descent updates weights to minimize loss in machine learning."
      ],
      "metadata": {
        "id": "A7_vxeAw-MAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(learning_rate=0.1, epochs=10):\n",
        "    # Initialize weight (à¤¶à¥à¤°à¥à¤†à¤¤à¥€ à¤µà¥‡à¤Ÿ)\n",
        "    w = 5\n",
        "\n",
        "    for i in range(epochs):  # Run for multiple epochs (à¤•à¤ˆ à¤¬à¤¾à¤° à¤…à¤ªà¤¡à¥‡à¤Ÿ à¤•à¤°à¥‡à¤‚)\n",
        "        gradient = 2 * w  # Compute derivative (à¤¡à¥‡à¤°à¤¿à¤µà¥‡à¤Ÿà¤¿à¤µ à¤¨à¤¿à¤•à¤¾à¤²à¤¨à¤¾)\n",
        "        w = w - learning_rate * gradient  # Update weight (à¤µà¥‡à¤Ÿ à¤…à¤ªà¤¡à¥‡à¤Ÿ à¤•à¤°à¤¨à¤¾)\n",
        "        print(f\"Epoch {i+1}: w = {w}\")  # Print weight after update (à¤…à¤ªà¤¡à¥‡à¤Ÿ à¤•à¥‡ à¤¬à¤¾à¤¦ à¤µà¥‡à¤Ÿ à¤¦à¤¿à¤–à¤¾à¤à¤‚)\n",
        "\n",
        "gradient_descent()  # Run the function (à¤«à¤‚à¤•à¥à¤¶à¤¨ à¤•à¥‹ à¤šà¤²à¤¾à¤à¤‚)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B75Awhy4-Qov",
        "outputId": "a0b41f97-8135-4ea8-dadb-ebe463d4d4da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: w = 4.0\n",
            "Epoch 2: w = 3.2\n",
            "Epoch 3: w = 2.56\n",
            "Epoch 4: w = 2.048\n",
            "Epoch 5: w = 1.6384\n",
            "Epoch 6: w = 1.31072\n",
            "Epoch 7: w = 1.0485760000000002\n",
            "Epoch 8: w = 0.8388608000000002\n",
            "Epoch 9: w = 0.6710886400000001\n",
            "Epoch 10: w = 0.5368709120000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "N92N3c0E_or6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3 Structure of Neural Networks\n",
        "Neural networks have three main layers:\n",
        "\n",
        "Input Layer: Takes raw data.\n",
        "Hidden Layers: Perform computations.\n",
        "Output Layer: Generates final predictions.\n",
        "Example 5: Creating a Simple Neural Network with TensorFlow"
      ],
      "metadata": {
        "id": "hYLbsYh4_o7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Creating a basic ANN model\n",
        "# à¤à¤• à¤¸à¤¾à¤§à¤¾à¤°à¤£ à¤¨à¥à¤¯à¥‚à¤°à¤² à¤¨à¥‡à¤Ÿà¤µà¤°à¥à¤• à¤®à¥‰à¤¡à¤² à¤¤à¥ˆà¤¯à¤¾à¤° à¤•à¤° à¤°à¤¹à¥‡ à¤¹à¥ˆà¤‚\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(4, activation='relu', input_shape=(3,)),  # Hidden Layer (à¤›à¥à¤ªà¥€ à¤¹à¥à¤ˆ à¤²à¥‡à¤¯à¤°)\n",
        "    keras.layers.Dense(1, activation='sigmoid')  # Output Layer (à¤†à¤‰à¤Ÿà¤ªà¥à¤Ÿ à¤²à¥‡à¤¯à¤°)\n",
        "])\n",
        "\n",
        "# Compile the model (à¤®à¥‰à¤¡à¤² à¤•à¥‹ à¤¸à¤‚à¤•à¤²à¤¿à¤¤ à¤•à¤°à¤¨à¤¾)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display model structure (à¤®à¥‰à¤¡à¤² à¤•à¥€ à¤¸à¤‚à¤°à¤šà¤¨à¤¾ à¤¦à¤¿à¤–à¤¾à¤à¤‚)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "g3FIc1Cw_tfo",
        "outputId": "5a2aa5b1-7ad2-4b0c-ba67-d690c1649aa9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   â”‚              \u001b[38;5;34m16\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   â”‚               \u001b[38;5;34m5\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21\u001b[0m (84.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> (84.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21\u001b[0m (84.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> (84.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example 6: Dense Layer vs. Sparse Connections"
      ],
      "metadata": {
        "id": "eyw8FvKR_4F5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Fully connected (Dense) neural network\n",
        "# à¤ªà¥‚à¤°à¥€ à¤¤à¤°à¤¹ à¤¸à¥‡ à¤œà¥à¤¡à¤¼à¥‡ à¤¹à¥à¤ à¤¨à¥à¤¯à¥‚à¤°à¥‰à¤¨à¥à¤¸ à¤•à¤¾ à¤à¤• à¤¨à¥‡à¤Ÿà¤µà¤°à¥à¤• à¤¬à¤¨à¤¾ à¤°à¤¹à¥‡ à¤¹à¥ˆà¤‚\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(5, activation='relu', input_shape=(3,)),  # Hidden layer with 5 neurons\n",
        "    Dense(1, activation='sigmoid')  # Output neuron\n",
        "])\n",
        "\n",
        "# Display model structure (à¤®à¥‰à¤¡à¤² à¤•à¤¾ à¤µà¤¿à¤µà¤°à¤£ à¤¦à¤¿à¤–à¤¾à¤à¤‚)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "ePXzP3p1_40S",
        "outputId": "f9832937-58fd-4237-8fa2-b298148e3dd0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   â”‚              \u001b[38;5;34m20\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   â”‚               \u001b[38;5;34m6\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26\u001b[0m (104.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> (104.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26\u001b[0m (104.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> (104.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Dense layers, all neurons are connected to each other, while in sparse layers (like CNNs), only a subset of neurons are connected."
      ],
      "metadata": {
        "id": "2HJgvaWZ_-9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EpD6kCAY__lR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4 Functional Units of ANN\n",
        "Neural networks are widely used for pattern recognition.\n",
        "\n",
        "Example 7: Perceptron for Binary Classification (AND Gate)"
      ],
      "metadata": {
        "id": "4UwH4b2X__sV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Training data for AND gate (AND à¤—à¥‡à¤Ÿ à¤•à¥‡ à¤²à¤¿à¤ à¤‡à¤¨à¤ªà¥à¤Ÿ à¤”à¤° à¤†à¤‰à¤Ÿà¤ªà¥à¤Ÿ)\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [0], [0], [1]])  # Expected output (AND à¤—à¥‡à¤Ÿ à¤•à¤¾ à¤¸à¤¹à¥€ à¤†à¤‰à¤Ÿà¤ªà¥à¤Ÿ)\n",
        "\n",
        "# Creating a perceptron model (à¤ªà¤°à¤¸à¥‡à¤ªà¥à¤Ÿà¥à¤°à¥‰à¤¨ à¤®à¥‰à¤¡à¤² à¤¬à¤¨à¤¾ à¤°à¤¹à¥‡ à¤¹à¥ˆà¤‚)\n",
        "model = Sequential([\n",
        "    Dense(1, activation='sigmoid', input_shape=(2,))\n",
        "])\n",
        "\n",
        "# Compile the model (à¤®à¥‰à¤¡à¤² à¤•à¥‹ à¤¸à¤‚à¤•à¤²à¤¿à¤¤ à¤•à¤°à¥‡à¤‚)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model (à¤®à¥‰à¤¡à¤² à¤•à¥‹ à¤Ÿà¥à¤°à¥‡à¤¨ à¤•à¤°à¥‡à¤‚)\n",
        "model.fit(X, y, epochs=100, verbose=0)\n",
        "\n",
        "# Predict the output (à¤†à¤‰à¤Ÿà¤ªà¥à¤Ÿ à¤¨à¤¿à¤•à¤¾à¤²à¥‡à¤‚)\n",
        "predictions = model.predict(X)\n",
        "print(\"Predictions:\", np.round(predictions))  # Display predictions (à¤ªà¥à¤°à¥‡à¤¡à¤¿à¤•à¥à¤¶à¤¨ à¤¦à¤¿à¤–à¤¾à¤à¤‚)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-_A5_nmACz2",
        "outputId": "0a0f03ec-75ea-4f4e-b461-d477109a0966"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Predictions: [[0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7P8-hCMAAPVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example 8: Concept of Epochs and Iterations\n",
        "Epoch: A full pass over the dataset.\n",
        "Iteration: One batch update during training."
      ],
      "metadata": {
        "id": "ihQo8U0ZAP3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Dummy dataset (à¤à¤• à¤›à¥‹à¤Ÿà¤¾ à¤¡à¥‡à¤Ÿà¤¾ à¤¸à¥‡à¤Ÿ)\n",
        "X = np.array([[1], [2], [3], [4]])  # Input values (à¤‡à¤¨à¤ªà¥à¤Ÿà¥à¤¸)\n",
        "y = np.array([[2], [4], [6], [8]])  # Expected output (à¤¸à¤¹à¥€ à¤†à¤‰à¤Ÿà¤ªà¥à¤Ÿ) => y = 2x\n",
        "\n",
        "# Define model (à¤®à¥‰à¤¡à¤² à¤¬à¤¨à¤¾à¤à¤‚)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_shape=(1,))\n",
        "])\n",
        "\n",
        "# Compile model (à¤®à¥‰à¤¡à¤² à¤•à¥‹ à¤¸à¤‚à¤•à¤²à¤¿à¤¤ à¤•à¤°à¥‡à¤‚)\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "\n",
        "# Train model with multiple epochs (à¤•à¤ˆ à¤¬à¤¾à¤° à¤Ÿà¥à¤°à¥‡à¤¨à¤¿à¤‚à¤— à¤•à¤°à¥‡à¤‚)\n",
        "history = model.fit(X, y, epochs=5, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1yhk1uWALqK",
        "outputId": "065ffaa4-7475-4a97-fa17-2dd0ade914c6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1.0652\n",
            "Epoch 2/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.7398\n",
            "Epoch 3/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.5140\n",
            "Epoch 4/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3573\n",
            "Epoch 5/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.2486\n"
          ]
        }
      ]
    }
  ]
}